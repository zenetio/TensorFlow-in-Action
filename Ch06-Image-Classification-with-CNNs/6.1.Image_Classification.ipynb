{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Teaching Machines to See\n",
    "\n",
    "## Image Classification\n",
    "\n",
    "In this, we will train a complex convolution neural network on an image classification dataset.\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch06-Image-Classification-with-CNNs/6.1.Image_Classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "random_seed = 4321\n",
    "# Fixing the random seed\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "\n",
    "For this chapter, we're going to use the tiny-imagenet dataset (200 categories of objects). This is a simplified version of the bigger and harder imagenet dataset (1000 categories of objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "#Section 6.1 \n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data','tiny-imagenet-200.zip')):\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','tiny-imagenet-200.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'tiny-imagenet-200')):\n",
    "    with zipfile.ZipFile(os.path.join('data','tiny-imagenet-200.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the label information of the data\n",
    "\n",
    "The classes in tiny-imagenet are coded by an id (known as `wnid` (WordNetID)). Here we will decode these IDs to get class descriptions of each ID, so we know what we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp\\ipykernel_16964\\4076525636.py:16: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  wnids = pd.read_csv(wnids_path, header=None, squeeze=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wnid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02124075</td>\n",
       "      <td>Egyptian cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n04067472</td>\n",
       "      <td>reel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n04540053</td>\n",
       "      <td>volleyball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04099969</td>\n",
       "      <td>rocking chair, rocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n07749582</td>\n",
       "      <td>lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n01641577</td>\n",
       "      <td>bullfrog, Rana catesbeiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n02802426</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n09246464</td>\n",
       "      <td>cliff, drop, drop-off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n07920052</td>\n",
       "      <td>espresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n03970156</td>\n",
       "      <td>plunger, plumber's helper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n03891332</td>\n",
       "      <td>parking meter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n02106662</td>\n",
       "      <td>German shepherd, German shepherd dog, German p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n03201208</td>\n",
       "      <td>dining table, board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n02279972</td>\n",
       "      <td>monarch, monarch butterfly, milkweed butterfly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n02132136</td>\n",
       "      <td>brown bear, bruin, Ursus arctos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n04146614</td>\n",
       "      <td>school bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n07873807</td>\n",
       "      <td>pizza, pizza pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n02364673</td>\n",
       "      <td>guinea pig, Cavia cobaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>n04507155</td>\n",
       "      <td>umbrella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>n03854065</td>\n",
       "      <td>organ, pipe organ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>n03838899</td>\n",
       "      <td>oboe, hautboy, hautbois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>n03733131</td>\n",
       "      <td>maypole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish, Carassius auratus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>n07875152</td>\n",
       "      <td>potpie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>n03544143</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wnid                                              class\n",
       "0   n02124075                                       Egyptian cat\n",
       "1   n04067472                                               reel\n",
       "2   n04540053                                         volleyball\n",
       "3   n04099969                              rocking chair, rocker\n",
       "4   n07749582                                              lemon\n",
       "5   n01641577                         bullfrog, Rana catesbeiana\n",
       "6   n02802426                                         basketball\n",
       "7   n09246464                              cliff, drop, drop-off\n",
       "8   n07920052                                           espresso\n",
       "9   n03970156                          plunger, plumber's helper\n",
       "10  n03891332                                      parking meter\n",
       "11  n02106662  German shepherd, German shepherd dog, German p...\n",
       "12  n03201208                                dining table, board\n",
       "13  n02279972  monarch, monarch butterfly, milkweed butterfly...\n",
       "14  n02132136                    brown bear, bruin, Ursus arctos\n",
       "15  n04146614                                         school bus\n",
       "16  n07873807                                   pizza, pizza pie\n",
       "17  n02364673                           guinea pig, Cavia cobaya\n",
       "18  n04507155                                           umbrella\n",
       "19  n03854065                                  organ, pipe organ\n",
       "20  n03838899                            oboe, hautboy, hautbois\n",
       "21  n03733131                                            maypole\n",
       "22  n01443537                        goldfish, Carassius auratus\n",
       "23  n07875152                                             potpie\n",
       "24  n03544143                                          hourglass"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Section 6.1\n",
    "#Code listing 6.1\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# The file paths we're going to use\n",
    "data_dir = os.path.join('data', 'tiny-imagenet-200')\n",
    "wnids_path = os.path.join(data_dir, 'wnids.txt')\n",
    "words_path = os.path.join(data_dir, 'words.txt')\n",
    "\n",
    "def get_tiny_imagenet_classes(wnids_path, words_path):\n",
    "    \n",
    "    # Read the csv files\n",
    "    # wninds.txt contains the wnids of the data in the dataset\n",
    "    wnids = pd.read_csv(wnids_path, header=None, squeeze=True)\n",
    "    # words.txt contains a mapping from wnid to the class description\n",
    "    words = pd.read_csv(words_path, sep='\\t', index_col=0, header=None)\n",
    "    # Get only the class descriptions corresponding to the wnids in the dataset\n",
    "    words_200 = words.loc[wnids].rename({1:'class'}, axis=1)\n",
    "    words_200.index.name = 'wnid'\n",
    "    return words_200.reset_index()\n",
    "\n",
    "labels = get_tiny_imagenet_classes(wnids_path, words_path)\n",
    "labels.head(n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pgfId-1116962\" href=\"\"></a><span class=\"fm-combinumeral\">#1</span> Imports pandas and os packages<br>\n",
    "<a id=\"pgfId-1116986\" href=\"\"></a><span class=\"fm-combinumeral\">#2</span> Defines paths of the data directory, wnids.txt, and words.txt files<br>\n",
    "<a id=\"pgfId-1117003\" href=\"\"></a><span class=\"fm-combinumeral\">#3</span> Defines a function to read the class descriptions of tiny_imagenet classes<br>\n",
    "<a id=\"pgfId-1117020\" href=\"\"></a><span class=\"fm-combinumeral\">#4</span> Reads wnids.txt and words.txt as CSV files using pandas<br>\n",
    "<a id=\"pgfId-1117037\" href=\"\"></a><span class=\"fm-combinumeral\">#5</span> Gets only the classes present in the tiny-imagenet-200 data set<br>\n",
    "<a id=\"pgfId-1117054\" href=\"\"></a><span class=\"fm-combinumeral\">#6</span> Sets the name of the index of the data frame to “wnid”<br>\n",
    "<a id=\"pgfId-1117071\" href=\"\"></a><span class=\"fm-combinumeral\">#7</span> Resets the index so that it becomes a column in the data frame (which has the column name “wnid”)<br>\n",
    "<a id=\"pgfId-1117088\" href=\"\"></a><span class=\"fm-combinumeral\">#8</span> Executes the function to obtain the class descriptions<br>\n",
    "<a class=\"calibre7\" id=\"pgfId-1117105\" href=\"\"></a><span class=\"fm-combinumeral\">#9</span> Inspects the head of the data frame (the first 25 entries)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many training instances for each class are there?\n",
    "\n",
    "**Note**: If you run this after separating out the validation data, you'll see 450 instead of 500 in the `n_train` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wnid</th>\n",
       "      <th>class</th>\n",
       "      <th>n_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02124075</td>\n",
       "      <td>Egyptian cat</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n04067472</td>\n",
       "      <td>reel</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n04540053</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04099969</td>\n",
       "      <td>rocking chair, rocker</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n07749582</td>\n",
       "      <td>lemon</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wnid                  class  n_train\n",
       "0  n02124075           Egyptian cat      500\n",
       "1  n04067472                   reel      500\n",
       "2  n04540053             volleyball      500\n",
       "3  n04099969  rocking chair, rocker      500\n",
       "4  n07749582                  lemon      500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Section 6.1\n",
    "\n",
    "import os\n",
    "def get_image_count(data_dir):  \n",
    "    \"\"\" Counts the number of jpeg files in a given folder\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        return 0\n",
    "    return len([f for f in os.listdir(data_dir) if f.lower().endswith('jpeg')])\n",
    "    \n",
    "# Here we use the apply function in conjunction with the get_image_count to get the count of images in each\n",
    "# subfolder in the train directory\n",
    "labels[\"n_train\"] = labels[\"wnid\"].apply(lambda x: get_image_count(os.path.join(data_dir, 'train', x, 'images')))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at summary statistics of the `n_train` column\n",
    "\n",
    "Summary statistics is a great way to get an instant view of a column in a dataframe. It gives us important information like mean/standard deviation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.0\n",
       "mean     500.0\n",
       "std        0.0\n",
       "min      500.0\n",
       "25%      500.0\n",
       "50%      500.0\n",
       "75%      500.0\n",
       "max      500.0\n",
       "Name: n_train, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"n_train\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the image dimensions in the dataset\n",
    "\n",
    "Before moving on to modelling we need to understand the image dimensions (height and width). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pgfId-1116035\" href=\"\"></a><span class=\"fm-combinumeral\">#1</span> Importing os, PIL, and pandas packages<br>\n",
    "<a id=\"pgfId-1116059\" href=\"\"></a><span class=\"fm-combinumeral\">#2</span> Defining a list to hold image sizes<br>\n",
    "<a id=\"pgfId-1116076\" href=\"\"></a><span class=\"fm-combinumeral\">#3</span> Looping through the first 25 classes in the data set<br>\n",
    "<a id=\"pgfId-1116093\" href=\"\"></a><span class=\"fm-combinumeral\">#4</span> Defining the image directory for a particular class within the loop<br>\n",
    "<a id=\"pgfId-1116110\" href=\"\"></a><span class=\"fm-combinumeral\">#5</span> Looping through all the images (ending with the extension JPEG) in that directory<br>\n",
    "<a id=\"pgfId-1116127\" href=\"\"></a><span class=\"fm-combinumeral\">#6</span> Appending the size of each image (i.e., a tuple of (width, height)) to image_sizes<br>\n",
    "<a id=\"pgfId-1116144\" href=\"\"></a><span class=\"fm-combinumeral\">#7</span> Creating a data frame from the tuples in the image_sizes<br>\n",
    "<a id=\"pgfId-1116161\" href=\"\"></a><span class=\"fm-combinumeral\">#8</span> Setting column names appropriately<br>\n",
    "<a class=\"calibre7\" id=\"pgfId-1116178\" href=\"\"></a><span class=\"fm-combinumeral\">#9</span> Obtaining the summary statistics of width and height for the images we fetched<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         width   height\n",
       "count  12500.0  12500.0\n",
       "mean      64.0     64.0\n",
       "std        0.0      0.0\n",
       "min       64.0     64.0\n",
       "25%       64.0     64.0\n",
       "50%       64.0     64.0\n",
       "75%       64.0     64.0\n",
       "max       64.0     64.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Section 6.1\n",
    "#Code listing 6.2\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# A list that will hold image height and width information\n",
    "image_sizes = []\n",
    "\n",
    "# We will only look at the first 25 directories (to save time)\n",
    "for wnid in labels[\"wnid\"].iloc[:25]:\n",
    "    img_dir = os.path.join('data', 'tiny-imagenet-200', 'train', wnid, 'images')\n",
    "    for f in os.listdir(img_dir):\n",
    "        # Only read the file if ends with JPEG\n",
    "        if f.endswith('JPEG'):\n",
    "            # Append the height and width to the list\n",
    "            # e.g. [(img1.width, img1.height), (img2.width, img2.height), ...]\n",
    "            image_sizes.append(Image.open(os.path.join(img_dir, f)).size)\n",
    "\n",
    "# Using the format of image_sizes, we can directly create a dataframe\n",
    "img_df = pd.DataFrame.from_records(image_sizes)\n",
    "img_df.columns = [\"width\", \"height\"]\n",
    "# Getting summary statistics of all columns\n",
    "img_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Getting information about pixel values of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.100000</td>\n",
       "      <td>-1.350000</td>\n",
       "      <td>121.372945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.383481</td>\n",
       "      <td>1.565248</td>\n",
       "      <td>40.301543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>63.183757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>98.160726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>112.580322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>127.742086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>227.127360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Min        Max        Mean\n",
       "count  20.000000  20.000000   20.000000\n",
       "mean    2.100000  -1.350000  121.372945\n",
       "std     7.383481   1.565248   40.301543\n",
       "min     0.000000  -8.000000   63.183757\n",
       "25%     0.000000  -1.000000   98.160726\n",
       "50%     0.000000  -1.000000  112.580322\n",
       "75%     0.000000  -1.000000  127.742086\n",
       "max    32.000000  -1.000000  227.127360"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "images = []\n",
    "for wnid in labels[\"wnid\"].iloc[:2]:\n",
    "    img_dir = os.path.join('data', 'tiny-imagenet-200', 'train', wnid, 'images')\n",
    "    for f in os.listdir(img_dir)[:10]:\n",
    "        if f.endswith('JPEG'):\n",
    "            img = np.array(Image.open(os.path.join(img_dir, f)))\n",
    "            images.append((img.min(), img.max(), img.mean()))\n",
    "\n",
    "img_df = pd.DataFrame.from_records(images)\n",
    "img_df.columns = [\"Min\", \"Max\", \"Mean\"]\n",
    "img_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data generators\n",
    "\n",
    "In the dataset, we currently have a,\n",
    "\n",
    "* Training set: `train` directory\n",
    "* Testing set: `val` directory\n",
    "\n",
    "But to properly train a model we need three datasets,\n",
    "\n",
    "* Training set - Used to train the model\n",
    "* Validation set - Used to continuously monitor model performance while training\n",
    "* Testing set - Used to test the model, only after training finishes\n",
    "\n",
    "Therefore, we will separate a 10% from training data and feed this data through as a separate generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "#Section 6.2\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def get_test_labels_df(test_labels_path):\n",
    "    \"\"\" Reading the test data labels for all files in the test set as a data frame \"\"\"\n",
    "    test_df = pd.read_csv(test_labels_path, sep='\\t', index_col=None, header=None)\n",
    "    test_df = test_df.iloc[:,[0,1]].rename({0:\"filename\", 1:\"class\"}, axis=1)\n",
    "    return test_df\n",
    "\n",
    "def get_train_valid_test_data_generators(batch_size, target_size):\n",
    "    # Define a Keras ImageDataGenerator with image centering (subtract mean)\n",
    "    \n",
    "    image_gen = ImageDataGenerator(samplewise_center=True, validation_split=0.1)\n",
    "\n",
    "    # Define a training data generator\n",
    "    partial_flow_func = partial(\n",
    "        image_gen.flow_from_directory, \n",
    "        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n",
    "        target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, \n",
    "        shuffle=True, seed=random_seed)\n",
    "    \n",
    "    # Get the training data subset\n",
    "    train_gen = partial_flow_func(subset='training')\n",
    "    # Get the validation data subset\n",
    "    valid_gen = partial_flow_func(subset='validation')\n",
    "    \n",
    "    \n",
    "    # Define a testing data generator\n",
    "    # This function uses flow_from_dataframe instead of flow_from_directory\n",
    "    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  'val', 'val_annotations.txt'))\n",
    "    test_gen = image_gen.flow_from_dataframe(\n",
    "        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "def data_gen_aux(gen):    \n",
    "    # We need to modify our standard data generators to output the same target three times\n",
    "    for x,y in gen:        \n",
    "        yield x,(y,y,y)\n",
    "\n",
    "batch_size = 128\n",
    "target_size = (56, 56)\n",
    "# Getting the train,valid, test data generators\n",
    "train_gen, valid_gen, test_gen = get_train_valid_test_data_generators(batch_size, target_size)\n",
    "# Modifying the data generators to fit the model targets\n",
    "train_gen_aux = data_gen_aux(train_gen)\n",
    "valid_gen_aux = data_gen_aux(valid_gen)\n",
    "test_gen_aux = data_gen_aux(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the consistency of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful! Labels across all trials were consistent.\n"
     ]
    }
   ],
   "source": [
    "from itertools import tee\n",
    "all_labels = []\n",
    "n_trials = 10\n",
    "\n",
    "valid_gen_test = tee(valid_gen, n_trials)\n",
    "\n",
    "for i in range(n_trials):    \n",
    "    labels = []\n",
    "    for j in range(5):\n",
    "        _, ohe = next(valid_gen_test[i])\n",
    "        # Convert one hot encoded to class labels\n",
    "        labels.append(np.argmax(ohe, axis=-1))\n",
    "        \n",
    "    # Concat all labels\n",
    "    labels = np.reshape(np.concatenate(labels, axis=0), (1,-1))        \n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Concat all labels accross all trials\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Assert the labels are equal across all trials\n",
    "assert np.all(np.all(all_labels == all_labels[0,:], axis=0)), \"Labels across multiple trials were not equal\"\n",
    "print(\"Successful! Labels across all trials were consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Inception net v1\n",
    "\n",
    "Here we will be creating the Inception net v1 model using Keras Functional API\n",
    "\n",
    "### Funtions that encapsulate various components of the Inception net v1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pgfId-1115389\" href=\"\"></a><span class=\"fm-combinumeral\">#1</span> The output of the first convolution layer<br>\n",
    "<a id=\"pgfId-1115410\" href=\"\"></a><span class=\"fm-combinumeral\">#2</span> The output of the first max pooling layer<br>\n",
    "<a id=\"pgfId-1115427\" href=\"\"></a><span class=\"fm-combinumeral\">#3</span> The first local response normalization layer. We define a lambda function that encapsulates LRN functionality.<br>\n",
    "<a id=\"pgfId-1115444\" href=\"\"></a><span class=\"fm-combinumeral\">#4</span> Subsequent convolution layers<br>\n",
    "<a id=\"pgfId-1115461\" href=\"\"></a><span class=\"fm-combinumeral\">#5</span> The second LRN layer<br>\n",
    "<a id=\"pgfId-1115481\" href=\"\"></a><span class=\"fm-combinumeral\">#6</span> Max pooling layer<br>\n",
    "<a class=\"calibre7\" id=\"pgfId-1115498\" href=\"\"></a><span class=\"fm-combinumeral\">#7</span> Returns the final output (i.e., output of the max pooling layer)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Section 6.3\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Code listing 6.3\n",
    "def stem(inp):\n",
    "    conv1 = Conv2D(64, (7,7), strides=(1,1), activation='relu', padding='same')(inp)\n",
    "    maxpool2 = MaxPool2D((3,3), strides=(2,2), padding='same')(conv1)\n",
    "    lrn3 = Lambda(lambda x: tf.nn.local_response_normalization(x))(maxpool2)\n",
    "\n",
    "    conv4 = Conv2D(64, (1,1), strides=(1,1), padding='same')(lrn3)\n",
    "    conv5 = Conv2D(192, (3,3), strides=(1,1), activation='relu', padding='same')(conv4)\n",
    "    lrn6 = Lambda(lambda x: tf.nn.local_response_normalization(x))(conv5)\n",
    "\n",
    "    maxpool7 = MaxPool2D((3,3), strides=(1,1), padding='same')(lrn6)\n",
    "\n",
    "    return maxpool7\n",
    "\n",
    "# Code listing 6.4\n",
    "def inception(inp, n_filters):\n",
    "\n",
    "    # 1x1 layer\n",
    "    # init argument defaults to glorot_uniform\n",
    "    out1 = Conv2D(n_filters[0][0], (1,1), strides=(1,1), activation='relu', padding='same')(inp)\n",
    "\n",
    "    # 1x1 followed by 3x3\n",
    "    out2_1 = Conv2D(n_filters[1][0], (1,1), strides=(1,1), activation='relu', padding='same')(inp)\n",
    "    out2_2 = Conv2D(n_filters[1][1], (3,3), strides=(1,1), activation='relu', padding='same')(out2_1)\n",
    "\n",
    "    # 1x1 followed by 5x5\n",
    "    out3_1 = Conv2D(n_filters[2][0], (1,1), strides=(1,1), activation='relu', padding='same')(inp)\n",
    "    out3_2 = Conv2D(n_filters[2][1], (5,5), strides=(1,1), activation='relu', padding='same')(out3_1)\n",
    "\n",
    "    # 3x3 (pool) followed by 1x1\n",
    "    out4_1 = MaxPool2D((3,3), strides=(1,1), padding='same')(inp)\n",
    "    out4_2 = Conv2D(n_filters[3][0], (1,1), strides=(1,1), activation='relu', padding='same')(out4_1)\n",
    "\n",
    "    out = Concatenate(axis=-1)([out1, out2_2, out3_2, out4_2])\n",
    "    return out\n",
    "\n",
    "# Code listing 6.5\n",
    "def aux_out(inp,name=None):    \n",
    "    avgpool1 = AvgPool2D((5,5), strides=(3,3), padding='valid')(inp)\n",
    "    conv1 = Conv2D(128, (1,1), activation='relu', padding='same')(avgpool1)\n",
    "    flat = Flatten()(conv1)\n",
    "    dense1 = Dense(1024, activation='relu')(flat)    \n",
    "    aux_out = Dense(200, activation='softmax', name=name)(dense1)\n",
    "    return aux_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pgfId-1114425\" href=\"\"></a><span class=\"fm-combinumeral\">#1</span> Defines an input layer. It takes a batch of 64 &times; 64 &times; 3-sized inputs.<br>\n",
    "<a id=\"pgfId-1114451\" href=\"\"></a><span class=\"fm-combinumeral\">#2</span> To define the stem, we use the previously defined stem() function.<br>\n",
    "<a id=\"pgfId-1114468\" href=\"\"></a><span class=\"fm-combinumeral\">#3</span> Defines Inception blocks. Note that each Inception block has different numbers of filters.<br>\n",
    "<a id=\"pgfId-1114485\" href=\"\"></a><span class=\"fm-combinumeral\">#4</span> Defines auxiliary outputs<br>\n",
    "<a id=\"pgfId-1114502\" href=\"\"></a><span class=\"fm-combinumeral\">#5</span> The final pooling layer is defined as an Average pooling layer.<br>\n",
    "<a id=\"pgfId-1114519\" href=\"\"></a><span class=\"fm-combinumeral\">#6</span> The Flatten layer flattens the average pooling layer and prepares it for the fully connected layers.<br>\n",
    "<a id=\"pgfId-1114536\" href=\"\"></a><span class=\"fm-combinumeral\">#7</span> The final prediction layer that has 200 output nodes (one for each class)<br>\n",
    "<a class=\"calibre7\" id=\"pgfId-1114553\" href=\"\"></a><span class=\"fm-combinumeral\">#8</span> When compiling the model, we use categorical cross-entropy loss for all the output layers and the optimizer adam.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 56, 56, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 56, 56, 64)   9472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 28, 28, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 28, 28, 64)   0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 28, 64)   4160        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 192)  110784      ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 28, 28, 192)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 192)  0          ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 28, 28, 96)   18528       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 16)   3088        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 28, 28, 128)  110720      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 32)   12832       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 28, 28, 32)   6176        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 28, 28, 128)  32896       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 28, 28, 32)   8224        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 28, 128)  32896       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 28, 28, 192)  221376      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 28, 28, 96)   76896       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 28, 28, 64)   16448       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 480)  0           ['conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 480)  0          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 14, 14, 96)   46176       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 14, 14, 16)   7696        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 480)  0          ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 14, 14, 192)  92352       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 14, 14, 208)  179920      ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 14, 14, 48)   19248       ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 14, 14, 64)   30784       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_15[0][0]',              \n",
      "                                                                  'conv2d_17[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]',              \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 14, 14, 112)  57456       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 14, 14, 24)   12312       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 14, 14, 160)  82080       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 14, 14, 224)  226016      ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 14, 14, 64)   38464       ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_21[0][0]',              \n",
      "                                                                  'conv2d_23[0][0]',              \n",
      "                                                                  'conv2d_25[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 14, 14, 128)  65664       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 14, 14, 24)   12312       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 14, 14, 128)  65664       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 14, 14, 256)  295168      ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 14, 14, 64)   38464       ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_28[0][0]',              \n",
      "                                                                  'conv2d_30[0][0]',              \n",
      "                                                                  'conv2d_32[0][0]',              \n",
      "                                                                  'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 14, 14, 144)  73872       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 14, 14, 32)   16416       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 14, 14, 112)  57456       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 14, 14, 288)  373536      ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 14, 14, 64)   51264       ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 14, 14, 528)  0           ['conv2d_34[0][0]',              \n",
      "                                                                  'conv2d_36[0][0]',              \n",
      "                                                                  'conv2d_38[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 14, 14, 160)  84640       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 14, 14, 32)   16928       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 14, 14, 528)  0          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 14, 14, 256)  135424      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 14, 14, 320)  461120      ['conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 14, 14, 128)  102528      ['conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 14, 14, 128)  67712       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 14, 14, 832)  0           ['conv2d_40[0][0]',              \n",
      "                                                                  'conv2d_42[0][0]',              \n",
      "                                                                  'conv2d_44[0][0]',              \n",
      "                                                                  'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 7, 7, 832)   0           ['concatenate_6[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 160)    133280      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 32)     26656       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 7, 7, 832)   0           ['max_pooling2d_10[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 256)    213248      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 320)    461120      ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 128)    102528      ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 128)    106624      ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 7, 7, 832)    0           ['conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_49[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 192)    159936      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 48)     39984       ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 7, 7, 832)   0           ['concatenate_7[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 384)    319872      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 384)    663936      ['conv2d_54[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 128)    153728      ['conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 128)    106624      ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 4, 4, 512)   0           ['concatenate_2[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 4, 4, 528)   0           ['concatenate_5[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 7, 7, 1024)   0           ['conv2d_53[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]',              \n",
      "                                                                  'conv2d_57[0][0]',              \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 128)    65664       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 4, 4, 128)    67712       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 1, 1, 1024)  0           ['concatenate_8[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1024)         0           ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         2098176     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         2098176     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " final (Dense)                  (None, 200)          205000      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " aux1 (Dense)                   (None, 200)          205000      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " aux2 (Dense)                   (None, 200)          205000      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,918,280\n",
      "Trainable params: 10,918,280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Section 6.3\n",
    "# Code listing 6.6\n",
    "def inception_v1():\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    inp = Input(shape=(56,56,3))\n",
    "    stem_out = stem(inp)\n",
    "    inc_3a = inception(stem_out, [(64,),(96,128),(16,32),(32,)])\n",
    "    inc_3b = inception(inc_3a, [(128,),(128,192),(32,96),(64,)])\n",
    "\n",
    "    maxpool = MaxPool2D((3,3), strides=(2,2), padding='same')(inc_3b)\n",
    "\n",
    "    inc_4a = inception(maxpool, [(192,),(96,208),(16,48),(64,)])\n",
    "    inc_4b = inception(inc_4a, [(160,),(112,224),(24,64),(64,)])\n",
    "\n",
    "    aux_out1 = aux_out(inc_4a, name='aux1')\n",
    "\n",
    "    inc_4c = inception(inc_4b, [(128,),(128,256),(24,64),(64,)])\n",
    "    inc_4d = inception(inc_4c, [(112,),(144,288),(32,64),(64,)])\n",
    "    inc_4e = inception(inc_4d, [(256,),(160,320),(32,128),(128,)])\n",
    "    \n",
    "    maxpool = MaxPool2D((3,3), strides=(2,2), padding='same')(inc_4e)\n",
    "    \n",
    "    aux_out2 = aux_out(inc_4d, name='aux2')\n",
    "\n",
    "    inc_5a = inception(maxpool, [(256,),(160,320),(32,128),(128,)])\n",
    "    inc_5b = inception(inc_5a, [(384,),(192,384),(48,128),(128,)])\n",
    "    avgpool1 = AvgPool2D((7,7), strides=(1,1), padding='valid')(inc_5b)\n",
    "\n",
    "    flat_out = Flatten()(avgpool1)\n",
    "    out_main = Dense(200, activation='softmax', name='final')(flat_out)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=[out_main, aux_out1, aux_out2])\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                       optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = inception_v1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pgfId-1114123\" href=\"\"></a><span class=\"fm-combinumeral\">#1</span> Creates a directory called eval to store the performance results<br>\n",
    "<a id=\"pgfId-1114166\" href=\"\"></a><span class=\"fm-combinumeral\">#2</span> This is a Keras callback that you pass to the fit() function. It writes the metrics data to a CSV file.<br>\n",
    "<a id=\"pgfId-1114183\" href=\"\"></a><span class=\"fm-combinumeral\">#3</span> By fitting the model, you can see that we are passing the train and validation data generators to the function.<br>\n",
    "<a class=\"calibre7\" id=\"pgfId-1114124\" href=\"\"></a><span class=\"fm-combinumeral\">#4</span> Saves the model to disk so it can be brought up again if needed<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.4\n",
    "\n",
    "def get_steps_per_epoch(n_data, batch_size):\n",
    "    \"\"\" Given the data size and batch size, gives the number of steps to travers the full dataset \"\"\"\n",
    "    if n_data%batch_size==0:\n",
    "        return int(n_data/batch_size)\n",
    "    else:\n",
    "        return int(n_data*1.0/batch_size)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "704/704 [==============================] - 3383s 5s/step - loss: 14.4716 - final_loss: 4.9109 - aux1_loss: 4.7385 - aux2_loss: 4.8222 - final_accuracy: 0.0284 - aux1_accuracy: 0.0485 - aux2_accuracy: 0.0395 - val_loss: 13.0250 - val_final_loss: 4.4794 - val_aux1_loss: 4.2198 - val_aux2_loss: 4.3259 - val_final_accuracy: 0.0672 - val_aux1_accuracy: 0.1006 - val_aux2_accuracy: 0.0847\n",
      "Epoch 2/50\n",
      "704/704 [==============================] - 254s 362ms/step - loss: 12.1630 - final_loss: 4.1942 - aux1_loss: 3.9210 - aux2_loss: 4.0478 - final_accuracy: 0.0991 - aux1_accuracy: 0.1433 - aux2_accuracy: 0.1221 - val_loss: 11.6344 - val_final_loss: 3.9679 - val_aux1_loss: 3.7699 - val_aux2_loss: 3.8966 - val_final_accuracy: 0.1332 - val_aux1_accuracy: 0.1702 - val_aux2_accuracy: 0.1476\n",
      "Epoch 3/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 10.8426 - final_loss: 3.7342 - aux1_loss: 3.4806 - aux2_loss: 3.6279 - final_accuracy: 0.1688 - aux1_accuracy: 0.2129 - aux2_accuracy: 0.1843 - val_loss: 10.5825 - val_final_loss: 3.5855 - val_aux1_loss: 3.4479 - val_aux2_loss: 3.5490 - val_final_accuracy: 0.1943 - val_aux1_accuracy: 0.2193 - val_aux2_accuracy: 0.2081\n",
      "Epoch 4/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 9.9165 - final_loss: 3.4125 - aux1_loss: 3.1803 - aux2_loss: 3.3237 - final_accuracy: 0.2239 - aux1_accuracy: 0.2646 - aux2_accuracy: 0.2385 - val_loss: 10.1976 - val_final_loss: 3.4305 - val_aux1_loss: 3.3412 - val_aux2_loss: 3.4258 - val_final_accuracy: 0.2230 - val_aux1_accuracy: 0.2413 - val_aux2_accuracy: 0.2247\n",
      "Epoch 5/50\n",
      "704/704 [==============================] - 98s 139ms/step - loss: 9.1885 - final_loss: 3.1669 - aux1_loss: 2.9320 - aux2_loss: 3.0896 - final_accuracy: 0.2680 - aux1_accuracy: 0.3101 - aux2_accuracy: 0.2789 - val_loss: 9.8419 - val_final_loss: 3.2864 - val_aux1_loss: 3.2452 - val_aux2_loss: 3.3103 - val_final_accuracy: 0.2546 - val_aux1_accuracy: 0.2644 - val_aux2_accuracy: 0.2473\n",
      "Epoch 6/50\n",
      "704/704 [==============================] - 96s 136ms/step - loss: 8.5304 - final_loss: 2.9496 - aux1_loss: 2.7063 - aux2_loss: 2.8745 - final_accuracy: 0.3079 - aux1_accuracy: 0.3498 - aux2_accuracy: 0.3167 - val_loss: 9.5759 - val_final_loss: 3.1464 - val_aux1_loss: 3.2015 - val_aux2_loss: 3.2279 - val_final_accuracy: 0.2820 - val_aux1_accuracy: 0.2704 - val_aux2_accuracy: 0.2681\n",
      "Epoch 7/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 7.9164 - final_loss: 2.7495 - aux1_loss: 2.4902 - aux2_loss: 2.6767 - final_accuracy: 0.3446 - aux1_accuracy: 0.3899 - aux2_accuracy: 0.3535 - val_loss: 9.6053 - val_final_loss: 3.1282 - val_aux1_loss: 3.2521 - val_aux2_loss: 3.2250 - val_final_accuracy: 0.2838 - val_aux1_accuracy: 0.2811 - val_aux2_accuracy: 0.2750\n",
      "Epoch 8/50\n",
      "704/704 [==============================] - 93s 132ms/step - loss: 7.3240 - final_loss: 2.5570 - aux1_loss: 2.2801 - aux2_loss: 2.4869 - final_accuracy: 0.3817 - aux1_accuracy: 0.4290 - aux2_accuracy: 0.3867 - val_loss: 9.5760 - val_final_loss: 3.0688 - val_aux1_loss: 3.2925 - val_aux2_loss: 3.2147 - val_final_accuracy: 0.3055 - val_aux1_accuracy: 0.2808 - val_aux2_accuracy: 0.2868\n",
      "Epoch 9/50\n",
      "704/704 [==============================] - 92s 131ms/step - loss: 6.7224 - final_loss: 2.3604 - aux1_loss: 2.0676 - aux2_loss: 2.2945 - final_accuracy: 0.4200 - aux1_accuracy: 0.4733 - aux2_accuracy: 0.4256 - val_loss: 9.6594 - val_final_loss: 3.0506 - val_aux1_loss: 3.3388 - val_aux2_loss: 3.2701 - val_final_accuracy: 0.3078 - val_aux1_accuracy: 0.2852 - val_aux2_accuracy: 0.2691\n",
      "Epoch 10/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 6.1361 - final_loss: 2.1632 - aux1_loss: 1.8617 - aux2_loss: 2.1112 - final_accuracy: 0.4588 - aux1_accuracy: 0.5156 - aux2_accuracy: 0.4613 - val_loss: 10.3868 - val_final_loss: 3.2850 - val_aux1_loss: 3.6028 - val_aux2_loss: 3.4990 - val_final_accuracy: 0.2970 - val_aux1_accuracy: 0.2709 - val_aux2_accuracy: 0.2775\n",
      "Epoch 11/50\n",
      "704/704 [==============================] - 93s 131ms/step - loss: 5.5039 - final_loss: 1.9459 - aux1_loss: 1.6440 - aux2_loss: 1.9139 - final_accuracy: 0.5031 - aux1_accuracy: 0.5620 - aux2_accuracy: 0.5027 - val_loss: 10.4378 - val_final_loss: 3.2832 - val_aux1_loss: 3.6572 - val_aux2_loss: 3.4974 - val_final_accuracy: 0.3032 - val_aux1_accuracy: 0.2791 - val_aux2_accuracy: 0.2795\n",
      "Epoch 12/50\n",
      "704/704 [==============================] - 93s 131ms/step - loss: 4.8697 - final_loss: 1.7209 - aux1_loss: 1.4331 - aux2_loss: 1.7158 - final_accuracy: 0.5510 - aux1_accuracy: 0.6108 - aux2_accuracy: 0.5451 - val_loss: 11.1979 - val_final_loss: 3.4467 - val_aux1_loss: 3.9712 - val_aux2_loss: 3.7799 - val_final_accuracy: 0.2963 - val_aux1_accuracy: 0.2640 - val_aux2_accuracy: 0.2638\n",
      "Epoch 13/50\n",
      "704/704 [==============================] - 92s 130ms/step - loss: 4.2891 - final_loss: 1.5030 - aux1_loss: 1.2461 - aux2_loss: 1.5400 - final_accuracy: 0.5965 - aux1_accuracy: 0.6549 - aux2_accuracy: 0.5827 - val_loss: 11.7419 - val_final_loss: 3.6158 - val_aux1_loss: 4.2323 - val_aux2_loss: 3.8939 - val_final_accuracy: 0.2925 - val_aux1_accuracy: 0.2551 - val_aux2_accuracy: 0.2588\n",
      "Epoch 14/50\n",
      "704/704 [==============================] - 93s 132ms/step - loss: 3.6765 - final_loss: 1.2657 - aux1_loss: 1.0577 - aux2_loss: 1.3532 - final_accuracy: 0.6531 - aux1_accuracy: 0.6996 - aux2_accuracy: 0.6245 - val_loss: 12.5096 - val_final_loss: 3.8386 - val_aux1_loss: 4.5561 - val_aux2_loss: 4.1149 - val_final_accuracy: 0.3008 - val_aux1_accuracy: 0.2577 - val_aux2_accuracy: 0.2697\n",
      "Epoch 15/50\n",
      "704/704 [==============================] - 92s 131ms/step - loss: 3.1456 - final_loss: 1.0568 - aux1_loss: 0.8937 - aux2_loss: 1.1951 - final_accuracy: 0.7028 - aux1_accuracy: 0.7388 - aux2_accuracy: 0.6632 - val_loss: 13.2423 - val_final_loss: 4.0920 - val_aux1_loss: 4.8331 - val_aux2_loss: 4.3172 - val_final_accuracy: 0.2987 - val_aux1_accuracy: 0.2596 - val_aux2_accuracy: 0.2630\n",
      "Epoch 16/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 2.6589 - final_loss: 0.8672 - aux1_loss: 0.7534 - aux2_loss: 1.0383 - final_accuracy: 0.7478 - aux1_accuracy: 0.7745 - aux2_accuracy: 0.7001 - val_loss: 14.5660 - val_final_loss: 4.4831 - val_aux1_loss: 5.3934 - val_aux2_loss: 4.6896 - val_final_accuracy: 0.2779 - val_aux1_accuracy: 0.2493 - val_aux2_accuracy: 0.2520\n",
      "Epoch 17/50\n",
      "704/704 [==============================] - 92s 131ms/step - loss: 2.2684 - final_loss: 0.7247 - aux1_loss: 0.6366 - aux2_loss: 0.9071 - final_accuracy: 0.7838 - aux1_accuracy: 0.8068 - aux2_accuracy: 0.7310 - val_loss: 15.7775 - val_final_loss: 4.8265 - val_aux1_loss: 5.8012 - val_aux2_loss: 5.1499 - val_final_accuracy: 0.2810 - val_aux1_accuracy: 0.2493 - val_aux2_accuracy: 0.2499\n",
      "Epoch 18/50\n",
      "704/704 [==============================] - 91s 130ms/step - loss: 1.9317 - final_loss: 0.6057 - aux1_loss: 0.5411 - aux2_loss: 0.7849 - final_accuracy: 0.8150 - aux1_accuracy: 0.8306 - aux2_accuracy: 0.7624 - val_loss: 17.2464 - val_final_loss: 5.3997 - val_aux1_loss: 6.2640 - val_aux2_loss: 5.5828 - val_final_accuracy: 0.2727 - val_aux1_accuracy: 0.2432 - val_aux2_accuracy: 0.2438\n",
      "Epoch 19/50\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 1.7006 - final_loss: 0.5215 - aux1_loss: 0.4744 - aux2_loss: 0.7047 - final_accuracy: 0.8388 - aux1_accuracy: 0.8497 - aux2_accuracy: 0.7839 - val_loss: 17.8414 - val_final_loss: 5.5956 - val_aux1_loss: 6.5303 - val_aux2_loss: 5.7155 - val_final_accuracy: 0.2764 - val_aux1_accuracy: 0.2462 - val_aux2_accuracy: 0.2479\n",
      "Epoch 20/50\n",
      "704/704 [==============================] - 91s 129ms/step - loss: 1.4971 - final_loss: 0.4604 - aux1_loss: 0.4159 - aux2_loss: 0.6207 - final_accuracy: 0.8550 - aux1_accuracy: 0.8654 - aux2_accuracy: 0.8076 - val_loss: 19.2543 - val_final_loss: 5.9852 - val_aux1_loss: 7.1444 - val_aux2_loss: 6.1247 - val_final_accuracy: 0.2693 - val_aux1_accuracy: 0.2413 - val_aux2_accuracy: 0.2448\n",
      "Epoch 21/50\n",
      "704/704 [==============================] - 93s 132ms/step - loss: 1.3580 - final_loss: 0.4179 - aux1_loss: 0.3777 - aux2_loss: 0.5624 - final_accuracy: 0.8671 - aux1_accuracy: 0.8778 - aux2_accuracy: 0.8237 - val_loss: 19.8316 - val_final_loss: 6.2799 - val_aux1_loss: 7.1723 - val_aux2_loss: 6.3794 - val_final_accuracy: 0.2688 - val_aux1_accuracy: 0.2442 - val_aux2_accuracy: 0.2456\n",
      "Epoch 22/50\n",
      "704/704 [==============================] - 93s 132ms/step - loss: 1.2599 - final_loss: 0.3978 - aux1_loss: 0.3519 - aux2_loss: 0.5101 - final_accuracy: 0.8740 - aux1_accuracy: 0.8856 - aux2_accuracy: 0.8381 - val_loss: 20.7417 - val_final_loss: 6.3228 - val_aux1_loss: 7.6019 - val_aux2_loss: 6.8171 - val_final_accuracy: 0.2696 - val_aux1_accuracy: 0.2446 - val_aux2_accuracy: 0.2357\n",
      "Epoch 23/50\n",
      "704/704 [==============================] - 92s 131ms/step - loss: 1.1298 - final_loss: 0.3520 - aux1_loss: 0.3123 - aux2_loss: 0.4655 - final_accuracy: 0.8884 - aux1_accuracy: 0.8972 - aux2_accuracy: 0.8509 - val_loss: 21.4796 - val_final_loss: 6.6225 - val_aux1_loss: 7.9050 - val_aux2_loss: 6.9522 - val_final_accuracy: 0.2697 - val_aux1_accuracy: 0.2421 - val_aux2_accuracy: 0.2441\n",
      "Epoch 24/50\n",
      "704/704 [==============================] - 97s 138ms/step - loss: 1.0989 - final_loss: 0.3555 - aux1_loss: 0.2939 - aux2_loss: 0.4495 - final_accuracy: 0.8878 - aux1_accuracy: 0.9042 - aux2_accuracy: 0.8568 - val_loss: 21.8328 - val_final_loss: 6.5528 - val_aux1_loss: 8.1216 - val_aux2_loss: 7.1584 - val_final_accuracy: 0.2672 - val_aux1_accuracy: 0.2470 - val_aux2_accuracy: 0.2371\n",
      "Epoch 25/50\n",
      "704/704 [==============================] - 97s 138ms/step - loss: 1.0250 - final_loss: 0.3343 - aux1_loss: 0.2802 - aux2_loss: 0.4104 - final_accuracy: 0.8940 - aux1_accuracy: 0.9078 - aux2_accuracy: 0.8665 - val_loss: 22.7405 - val_final_loss: 6.8227 - val_aux1_loss: 8.5200 - val_aux2_loss: 7.3978 - val_final_accuracy: 0.2740 - val_aux1_accuracy: 0.2322 - val_aux2_accuracy: 0.2391\n",
      "Epoch 26/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 0.9827 - final_loss: 0.3108 - aux1_loss: 0.2788 - aux2_loss: 0.3930 - final_accuracy: 0.9022 - aux1_accuracy: 0.9094 - aux2_accuracy: 0.8729 - val_loss: 22.5963 - val_final_loss: 6.9202 - val_aux1_loss: 8.2974 - val_aux2_loss: 7.3787 - val_final_accuracy: 0.2655 - val_aux1_accuracy: 0.2450 - val_aux2_accuracy: 0.2355\n",
      "Epoch 27/50\n",
      "704/704 [==============================] - 94s 133ms/step - loss: 0.9636 - final_loss: 0.3176 - aux1_loss: 0.2663 - aux2_loss: 0.3797 - final_accuracy: 0.8993 - aux1_accuracy: 0.9135 - aux2_accuracy: 0.8769 - val_loss: 23.3546 - val_final_loss: 7.0498 - val_aux1_loss: 8.5164 - val_aux2_loss: 7.7883 - val_final_accuracy: 0.2742 - val_aux1_accuracy: 0.2382 - val_aux2_accuracy: 0.2501\n",
      "Epoch 28/50\n",
      "704/704 [==============================] - 96s 137ms/step - loss: 0.8820 - final_loss: 0.2871 - aux1_loss: 0.2445 - aux2_loss: 0.3504 - final_accuracy: 0.9091 - aux1_accuracy: 0.9205 - aux2_accuracy: 0.8880 - val_loss: 23.1654 - val_final_loss: 7.0563 - val_aux1_loss: 8.4545 - val_aux2_loss: 7.6547 - val_final_accuracy: 0.2669 - val_aux1_accuracy: 0.2447 - val_aux2_accuracy: 0.2316\n",
      "Epoch 29/50\n",
      "704/704 [==============================] - 96s 136ms/step - loss: 0.8902 - final_loss: 0.2973 - aux1_loss: 0.2439 - aux2_loss: 0.3490 - final_accuracy: 0.9064 - aux1_accuracy: 0.9209 - aux2_accuracy: 0.8871 - val_loss: 23.9376 - val_final_loss: 7.3560 - val_aux1_loss: 8.7278 - val_aux2_loss: 7.8538 - val_final_accuracy: 0.2654 - val_aux1_accuracy: 0.2410 - val_aux2_accuracy: 0.2404\n",
      "Epoch 30/50\n",
      "704/704 [==============================] - 96s 137ms/step - loss: 0.8603 - final_loss: 0.2867 - aux1_loss: 0.2349 - aux2_loss: 0.3387 - final_accuracy: 0.9101 - aux1_accuracy: 0.9238 - aux2_accuracy: 0.8919 - val_loss: 23.8941 - val_final_loss: 7.1059 - val_aux1_loss: 8.9512 - val_aux2_loss: 7.8369 - val_final_accuracy: 0.2721 - val_aux1_accuracy: 0.2388 - val_aux2_accuracy: 0.2333\n",
      "Epoch 31/50\n",
      "704/704 [==============================] - 97s 138ms/step - loss: 0.8144 - final_loss: 0.2761 - aux1_loss: 0.2171 - aux2_loss: 0.3212 - final_accuracy: 0.9138 - aux1_accuracy: 0.9293 - aux2_accuracy: 0.8962 - val_loss: 24.5678 - val_final_loss: 7.3210 - val_aux1_loss: 9.0834 - val_aux2_loss: 8.1634 - val_final_accuracy: 0.2704 - val_aux1_accuracy: 0.2401 - val_aux2_accuracy: 0.2387\n",
      "Epoch 32/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 0.8319 - final_loss: 0.2858 - aux1_loss: 0.2227 - aux2_loss: 0.3234 - final_accuracy: 0.9093 - aux1_accuracy: 0.9275 - aux2_accuracy: 0.8963 - val_loss: 24.6427 - val_final_loss: 7.3709 - val_aux1_loss: 9.1475 - val_aux2_loss: 8.1243 - val_final_accuracy: 0.2618 - val_aux1_accuracy: 0.2421 - val_aux2_accuracy: 0.2433\n",
      "Epoch 33/50\n",
      "704/704 [==============================] - 94s 133ms/step - loss: 0.7667 - final_loss: 0.2647 - aux1_loss: 0.2036 - aux2_loss: 0.2984 - final_accuracy: 0.9173 - aux1_accuracy: 0.9339 - aux2_accuracy: 0.9041 - val_loss: 25.3499 - val_final_loss: 7.5938 - val_aux1_loss: 9.2933 - val_aux2_loss: 8.4628 - val_final_accuracy: 0.2647 - val_aux1_accuracy: 0.2381 - val_aux2_accuracy: 0.2450\n",
      "Epoch 34/50\n",
      "704/704 [==============================] - 94s 133ms/step - loss: 0.7829 - final_loss: 0.2671 - aux1_loss: 0.2139 - aux2_loss: 0.3019 - final_accuracy: 0.9161 - aux1_accuracy: 0.9307 - aux2_accuracy: 0.9028 - val_loss: 25.1604 - val_final_loss: 7.6108 - val_aux1_loss: 9.1756 - val_aux2_loss: 8.3739 - val_final_accuracy: 0.2789 - val_aux1_accuracy: 0.2382 - val_aux2_accuracy: 0.2366\n",
      "Epoch 35/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 0.7606 - final_loss: 0.2621 - aux1_loss: 0.2079 - aux2_loss: 0.2906 - final_accuracy: 0.9162 - aux1_accuracy: 0.9321 - aux2_accuracy: 0.9069 - val_loss: 25.1262 - val_final_loss: 7.4309 - val_aux1_loss: 9.3398 - val_aux2_loss: 8.3556 - val_final_accuracy: 0.2588 - val_aux1_accuracy: 0.2367 - val_aux2_accuracy: 0.2372\n",
      "Epoch 36/50\n",
      "704/704 [==============================] - 100s 142ms/step - loss: 0.7398 - final_loss: 0.2568 - aux1_loss: 0.1947 - aux2_loss: 0.2883 - final_accuracy: 0.9193 - aux1_accuracy: 0.9371 - aux2_accuracy: 0.9081 - val_loss: 25.3132 - val_final_loss: 7.4614 - val_aux1_loss: 9.3484 - val_aux2_loss: 8.5034 - val_final_accuracy: 0.2714 - val_aux1_accuracy: 0.2465 - val_aux2_accuracy: 0.2407\n",
      "Epoch 37/50\n",
      "704/704 [==============================] - 97s 137ms/step - loss: 0.7240 - final_loss: 0.2561 - aux1_loss: 0.1856 - aux2_loss: 0.2824 - final_accuracy: 0.9193 - aux1_accuracy: 0.9403 - aux2_accuracy: 0.9095 - val_loss: 25.9445 - val_final_loss: 7.6575 - val_aux1_loss: 9.6331 - val_aux2_loss: 8.6538 - val_final_accuracy: 0.2635 - val_aux1_accuracy: 0.2329 - val_aux2_accuracy: 0.2315\n",
      "Epoch 38/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 0.7199 - final_loss: 0.2477 - aux1_loss: 0.1951 - aux2_loss: 0.2771 - final_accuracy: 0.9214 - aux1_accuracy: 0.9374 - aux2_accuracy: 0.9104 - val_loss: 25.6702 - val_final_loss: 7.6665 - val_aux1_loss: 9.5650 - val_aux2_loss: 8.4387 - val_final_accuracy: 0.2714 - val_aux1_accuracy: 0.2377 - val_aux2_accuracy: 0.2351\n",
      "Epoch 39/50\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.6994 - final_loss: 0.2452 - aux1_loss: 0.1891 - aux2_loss: 0.2651 - final_accuracy: 0.9232 - aux1_accuracy: 0.9385 - aux2_accuracy: 0.9138 - val_loss: 25.7860 - val_final_loss: 7.5489 - val_aux1_loss: 9.5355 - val_aux2_loss: 8.7015 - val_final_accuracy: 0.2661 - val_aux1_accuracy: 0.2418 - val_aux2_accuracy: 0.2329\n",
      "Epoch 40/50\n",
      "704/704 [==============================] - 91s 129ms/step - loss: 0.6954 - final_loss: 0.2497 - aux1_loss: 0.1770 - aux2_loss: 0.2688 - final_accuracy: 0.9217 - aux1_accuracy: 0.9420 - aux2_accuracy: 0.9146 - val_loss: 26.2869 - val_final_loss: 7.8008 - val_aux1_loss: 9.8301 - val_aux2_loss: 8.6560 - val_final_accuracy: 0.2753 - val_aux1_accuracy: 0.2420 - val_aux2_accuracy: 0.2425\n",
      "Epoch 41/50\n",
      "704/704 [==============================] - 90s 129ms/step - loss: 0.6798 - final_loss: 0.2417 - aux1_loss: 0.1823 - aux2_loss: 0.2559 - final_accuracy: 0.9241 - aux1_accuracy: 0.9407 - aux2_accuracy: 0.9172 - val_loss: 26.9418 - val_final_loss: 8.0771 - val_aux1_loss: 9.8449 - val_aux2_loss: 9.0198 - val_final_accuracy: 0.2689 - val_aux1_accuracy: 0.2351 - val_aux2_accuracy: 0.2316\n",
      "Epoch 42/50\n",
      "704/704 [==============================] - 91s 129ms/step - loss: 0.6591 - final_loss: 0.2341 - aux1_loss: 0.1740 - aux2_loss: 0.2510 - final_accuracy: 0.9264 - aux1_accuracy: 0.9441 - aux2_accuracy: 0.9199 - val_loss: 26.1059 - val_final_loss: 7.7401 - val_aux1_loss: 9.6359 - val_aux2_loss: 8.7298 - val_final_accuracy: 0.2692 - val_aux1_accuracy: 0.2420 - val_aux2_accuracy: 0.2417\n",
      "Epoch 43/50\n",
      "704/704 [==============================] - 95s 135ms/step - loss: 0.6442 - final_loss: 0.2313 - aux1_loss: 0.1722 - aux2_loss: 0.2407 - final_accuracy: 0.9274 - aux1_accuracy: 0.9446 - aux2_accuracy: 0.9221 - val_loss: 26.5297 - val_final_loss: 7.7512 - val_aux1_loss: 10.0683 - val_aux2_loss: 8.7102 - val_final_accuracy: 0.2643 - val_aux1_accuracy: 0.2328 - val_aux2_accuracy: 0.2327\n",
      "Epoch 44/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 0.6505 - final_loss: 0.2313 - aux1_loss: 0.1734 - aux2_loss: 0.2458 - final_accuracy: 0.9271 - aux1_accuracy: 0.9440 - aux2_accuracy: 0.9215 - val_loss: 26.3792 - val_final_loss: 7.8592 - val_aux1_loss: 9.8510 - val_aux2_loss: 8.6690 - val_final_accuracy: 0.2649 - val_aux1_accuracy: 0.2349 - val_aux2_accuracy: 0.2371\n",
      "Epoch 45/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 0.6478 - final_loss: 0.2374 - aux1_loss: 0.1699 - aux2_loss: 0.2406 - final_accuracy: 0.9257 - aux1_accuracy: 0.9450 - aux2_accuracy: 0.9230 - val_loss: 26.6121 - val_final_loss: 7.9305 - val_aux1_loss: 9.8802 - val_aux2_loss: 8.8015 - val_final_accuracy: 0.2596 - val_aux1_accuracy: 0.2364 - val_aux2_accuracy: 0.2397\n",
      "Epoch 46/50\n",
      "704/704 [==============================] - 96s 136ms/step - loss: 0.6160 - final_loss: 0.2180 - aux1_loss: 0.1625 - aux2_loss: 0.2355 - final_accuracy: 0.9314 - aux1_accuracy: 0.9476 - aux2_accuracy: 0.9244 - val_loss: 27.4643 - val_final_loss: 8.2336 - val_aux1_loss: 10.2542 - val_aux2_loss: 8.9765 - val_final_accuracy: 0.2659 - val_aux1_accuracy: 0.2351 - val_aux2_accuracy: 0.2363\n",
      "Epoch 47/50\n",
      "704/704 [==============================] - 96s 137ms/step - loss: 0.6366 - final_loss: 0.2263 - aux1_loss: 0.1658 - aux2_loss: 0.2445 - final_accuracy: 0.9289 - aux1_accuracy: 0.9471 - aux2_accuracy: 0.9217 - val_loss: 26.6987 - val_final_loss: 8.0182 - val_aux1_loss: 9.8644 - val_aux2_loss: 8.8161 - val_final_accuracy: 0.2635 - val_aux1_accuracy: 0.2393 - val_aux2_accuracy: 0.2395\n",
      "Epoch 48/50\n",
      "704/704 [==============================] - 94s 133ms/step - loss: 0.5996 - final_loss: 0.2169 - aux1_loss: 0.1598 - aux2_loss: 0.2229 - final_accuracy: 0.9332 - aux1_accuracy: 0.9485 - aux2_accuracy: 0.9283 - val_loss: 27.9334 - val_final_loss: 8.3595 - val_aux1_loss: 10.4360 - val_aux2_loss: 9.1378 - val_final_accuracy: 0.2699 - val_aux1_accuracy: 0.2325 - val_aux2_accuracy: 0.2406\n",
      "Epoch 49/50\n",
      "704/704 [==============================] - 94s 133ms/step - loss: 0.6155 - final_loss: 0.2264 - aux1_loss: 0.1582 - aux2_loss: 0.2309 - final_accuracy: 0.9309 - aux1_accuracy: 0.9489 - aux2_accuracy: 0.9252 - val_loss: 27.0934 - val_final_loss: 8.0312 - val_aux1_loss: 10.1376 - val_aux2_loss: 8.9246 - val_final_accuracy: 0.2637 - val_aux1_accuracy: 0.2353 - val_aux2_accuracy: 0.2397\n",
      "Epoch 50/50\n",
      "704/704 [==============================] - 94s 134ms/step - loss: 0.5752 - final_loss: 0.2059 - aux1_loss: 0.1568 - aux2_loss: 0.2125 - final_accuracy: 0.9360 - aux1_accuracy: 0.9493 - aux2_accuracy: 0.9316 - val_loss: 27.4606 - val_final_loss: 8.0466 - val_aux1_loss: 10.3241 - val_aux2_loss: 9.0900 - val_final_accuracy: 0.2721 - val_aux1_accuracy: 0.2339 - val_aux2_accuracy: 0.2373\n",
      "It took 8192.102078676224 seconds to complete the training\n"
     ]
    }
   ],
   "source": [
    "# Section 6.4\n",
    "# Code listing 6.7\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Create a directory called eval which stores model performance\n",
    "if not os.path.exists('eval'):\n",
    "    os.mkdir('eval')\n",
    "    \n",
    "# This will automatically log model performan to this file\n",
    "csv_logger = CSVLogger(os.path.join('eval','1_eval_base.log'))\n",
    "    \n",
    "t1 = time.time() # Starting time\n",
    "\n",
    "# Train the model, not how we are specifying steps_per_epoch and validation_steps\n",
    "# to prevent the model from training forever\n",
    "# We are also using the data generators (not actual data loaded to memory) to train the model\n",
    "history = model.fit(\n",
    "    train_gen_aux, validation_data=valid_gen_aux, \n",
    "    steps_per_epoch=get_steps_per_epoch(0.9*500*200,batch_size), \n",
    "    validation_steps=get_steps_per_epoch(0.1*500*200,batch_size),\n",
    "    epochs=50, callbacks=[csv_logger]\n",
    ")\n",
    "t2 = time.time() # Ending time\n",
    "\n",
    "# Print time it took\n",
    "print(\"It took {} seconds to complete the training\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Metrics of the model\n",
    "\n",
    "This is a multi output model. So it pays off to check what are the metrics that the model uses. You can get metric names by calling `model.metrics_names` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'final_loss', 'aux1_loss', 'aux2_loss', 'final_accuracy', 'aux1_accuracy', 'aux2_accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
    "plt.plot(history.history['final_loss'])\n",
    "plt.plot(history.history['final_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to models directory\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "model.save(os.path.join('models', 'inception_v1_base.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test accuracy of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 56s 280ms/step - loss: 27.5944 - final_loss: 8.1725 - aux1_loss: 10.2609 - aux2_loss: 9.1610 - final_accuracy: 0.2710 - aux1_accuracy: 0.2435 - aux2_accuracy: 0.2391\n",
      "{'loss': 27.594390869140625, 'final_loss': 8.17249584197998, 'aux1_loss': 10.260876655578613, 'aux2_loss': 9.161019325256348, 'final_accuracy': 0.2710344195365906, 'aux1_accuracy': 0.24352477490901947, 'aux2_accuracy': 0.23906049132347107}\n"
     ]
    }
   ],
   "source": [
    "# Section 6.4\n",
    "\n",
    "# Load the model from disk\n",
    "model = load_model(os.path.join('models','inception_v1_base.h5'))\n",
    "\n",
    "# Evaluate the model\n",
    "test_res = model.evaluate(test_gen_aux, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('manning.tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a5eda5f6f277a35ee74e53c7ea4300c8d4d4a1e37dd21ebec0e7d7b2134f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
