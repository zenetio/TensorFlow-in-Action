{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring models (Tensorboard)\n",
    "\n",
    "Montiroing models is crucial part when training a model. Continuous monitoring of the model enables to ensure the model training is functioning as intended. Furthermore, it can also provide insights to improvements that can be made to improve model performance and execution time. Here, we will see how we can use the TensorBoard to continuously monitor the model, profile the model as well as visualize various data types such as images and text.\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch14-Tensorboard/14.1_Tensorboard.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important checks before running this code\n",
    "\n",
    "## Setting the `TF_GPU_THREAD_MODE` variable\n",
    "\n",
    "This variable will be something we'll be changing later in the code. The change you do will be persistent. Therefore, if you run this notebook multiple times, you'll be starting running the code with this variable set to a different value than the default. To avoid that, \n",
    "* Stop the Jupyter notebook server\n",
    "* Set this environment variable `TF_GPU_THREAD_MODE=global` which is the default value. To do that, follow the instructions avalable at [this section](#set_environment) **with `global` as the value instead of `gpu_private`** to undo the changes.\n",
    "* Restart the Juptyer notebook server\n",
    "\n",
    "## Installing Model profiling with CUDA\n",
    "In order to make sure all the features of the Tensorboard work, make sure to install the `libcupti` library. It stands for **Lib**rary - **CU**DA **P**rofiling **T**ools **I**nterface. It is a GPU profiling toolkit by NVIDIA, which is required by the Tensboard profiling dashboard.\n",
    "\n",
    "### Linux Installation - `libcupti`\n",
    "On linux you can install this using `sudo apt-get install libcupti-dev`.\n",
    "\n",
    "### Windows Installation - `libcupti`\n",
    "\n",
    "As opposed to the Linux installation, Windows installation require more work.\n",
    "\n",
    "* Make sure you have installed the required CUDA installation (e.g. CUDA 11 [>= TensorFlow 2.4.0])\n",
    "* Next, open the NVIDIA Control Panel to do several changes (These were suggested in the following [Github issue](https://github.com/tensorflow/tensorflow/issues/35860#issuecomment-603728531)),\n",
    "  * Make sure you have set the Developer Mode by clicking Desktop > Set Developer Mode\n",
    "  * Make sure you have enabled GPU profiling to all users and not just the adiministrator. \n",
    "* For more errors you might face, refer the following page from the official [NVIDIA website](https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti)\n",
    "* To install `libcupti` (Motivated by this [Stackoverflow question](https://stackoverflow.com/questions/54028188/how-to-install-cuda-profiling-tools-interface-on-windows-10/54029753)),\n",
    "  * Copy `libcupti_<version>.dll`, `nvperf_host.dll` and `nvperf_target.dll` from the `extras\\CUPTI\\lib64` to the `bin` folder. Make sure the `libcupti` file has the name, `libcupti_110.dll`.\n",
    "  * Copy all files in the `extras\\CUPTI\\lib64` to `lib\\x64`\n",
    "  * Copy all files in the `extras\\CUPTI\\include` to `include`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed=4321\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "log_datetimestamp_format = \"%Y%m%d%H%M%S\"\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('logs'):\n",
    "    shutil.rmtree('logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Image Data on the TensorBoard\n",
    "\n",
    "First we're going to visualize some image data on the TensorBoard. This is done by logging some sample images to a specific directory, which is monitored by the TensorBoard for any incoming data.\n",
    "\n",
    "## Importing the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>, 'train': <PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}\n"
     ]
    }
   ],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "fashion_ds = tfds.load('fashion_mnist')\n",
    "\n",
    "print(fashion_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation/testing data\n",
    "\n",
    "As we have done before, let's separate the data to training, validation and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14.1\n",
    "\n",
    "# Code listing 14.1\n",
    "def get_train_valid_test_datasets(fashion_ds, batch_size, flatten_images=False):\n",
    "    \n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label) \n",
    "    train_ds = fashion_ds[\"train\"].shuffle(batch_size*20).map(lambda xy: (xy[\"image\"], tf.reshape(xy[\"label\"], [-1])))\n",
    "    # Get the testing dataset, and output a tuple of (image, label)\n",
    "    test_ds = fashion_ds[\"test\"].map(lambda xy: (xy[\"image\"], tf.reshape(xy[\"label\"], [-1])))\n",
    "    \n",
    "    if flatten_images:\n",
    "        # Flatten the images to a 1D vector for fully-connected networks\n",
    "        train_ds = train_ds.map(lambda x,y: (tf.reshape(x, [-1]), y))\n",
    "        test_ds = test_ds.map(lambda x,y: (tf.reshape(x, [-1]), y))\n",
    "    \n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = train_ds.take(10000).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = train_ds.skip(10000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `tf.summary` to visualize images on TensorBoard\n",
    "\n",
    "When logging data to be shown on the TensorBoard, they are logged as `tf.summary` type objects. Since we're working with images here, we'll use `tf.summary.image` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to the tensorboard\n",
      "\tDone\n"
     ]
    }
   ],
   "source": [
    "# Section 14.1\n",
    "\n",
    "# Defining the ID to Label map\n",
    "id2label_map = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2:\"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "print(\"Writing to the tensorboard\")\n",
    "\n",
    "log_datetimestamp = datetime.strftime(datetime.now(), log_datetimestamp_format)\n",
    "image_logdir = \"./logs/data_{}/train\".format(log_datetimestamp)\n",
    "\n",
    "# Define a summary writer\n",
    "image_writer = tf.summary.create_file_writer(image_logdir)\n",
    "\n",
    "# Write an image with its category\n",
    "with image_writer.as_default():\n",
    "    for data in fashion_ds[\"train\"].batch(1).take(10):\n",
    "        tf.summary.image(id2label_map[int(data[\"label\"].numpy())], data[\"image\"], max_outputs=20, step=0)\n",
    "\n",
    "# Write a batch of images at once\n",
    "with image_writer.as_default():\n",
    "    for data in fashion_ds[\"train\"].batch(20).take(1):\n",
    "        pass\n",
    "    tf.summary.image(\"A training data batch\", data[\"image\"], max_outputs=20, step=0)\n",
    "\n",
    "print('\\tDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spinning up the TensorBoard\n",
    " \n",
    "Here we're using tensorboard magic command on jupyter notebook. This gives us the TensorBoard inline, as if you were to open the Tensorboard in a browser tab. If you call the same command multiple times with the same `logdir` it will reuse the same Tensorboard. If the directories are different a new TensorBoard is spun up. \n",
    "\n",
    "There are times you have to restart the TensorBoard to get a fresh view of the logged data. For that,\n",
    "\n",
    "On Linux,\n",
    "* Open a command line terminal and execute `ps -ef|grep tensorboard`. This will give the process ID of TensorBoard\n",
    "* Execute `kill -9 <TensorBoard process ID>` to kill the process.\n",
    "\n",
    "On Windows,\n",
    "* Execute the following two lines in the Jupyter notebook\n",
    "* `!taskkill /IM \"tensorboard.exe\" /F`\n",
    "* `!rmdir /s /q C:\\Users\\<user name>\\AppData\\Local\\Temp\\.tensorboard-info`\n",
    "\n",
    "**Note**: On windows, it's not just enough to kill the process to restart the tensorboard. You have to delete the `C:\\Users\\<user name>\\AppData\\Local\\Temp\\.tensorboard-info` directory as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26792), started 0:19:27 ago. (Use '!kill 26792' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e49bec741188ebb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e49bec741188ebb\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Open [Tensorboard](http://localhost:6006) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking models on TensorBoard\n",
    "\n",
    "Here we will compare two models; \n",
    "* a fully-connected model and \n",
    "* a convolutional neural network. \n",
    "To compare them we will use the Fashion-MNIST dataset.\n",
    "\n",
    "## Monitoring the performance of the fully-connected network\n",
    "\n",
    "Here we analyse the training and validation performance of the fully-connected network. We will track loss and accuracy of the model.\n",
    "\n",
    "### Fully-connected network\n",
    "\n",
    "Here we define a fully connected network with 3 layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14.2\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "dense_model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 8s 6ms/step - loss: 3.3363 - accuracy: 0.7684 - val_loss: 0.7932 - val_accuracy: 0.7902\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5676 - accuracy: 0.8219 - val_loss: 0.5358 - val_accuracy: 0.8330\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4724 - accuracy: 0.8399 - val_loss: 0.4721 - val_accuracy: 0.8486\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4346 - accuracy: 0.8487 - val_loss: 0.4979 - val_accuracy: 0.8339\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4263 - accuracy: 0.8490 - val_loss: 0.4426 - val_accuracy: 0.8449\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4054 - accuracy: 0.8557 - val_loss: 0.4183 - val_accuracy: 0.8574\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3759 - accuracy: 0.8649 - val_loss: 0.4414 - val_accuracy: 0.8556\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3666 - accuracy: 0.8686 - val_loss: 0.4361 - val_accuracy: 0.8480\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3538 - accuracy: 0.8716 - val_loss: 0.3770 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3386 - accuracy: 0.8772 - val_loss: 0.4262 - val_accuracy: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b0b97b640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 14.2\n",
    "\n",
    "log_datetimestamp = datetime.strftime(datetime.now(), log_datetimestamp_format)\n",
    "dense_log_dir = os.path.join(\"logs\",\"dense_{}\".format(log_datetimestamp))\n",
    "\n",
    "batch_size = 64\n",
    "tr_ds, v_ds, ts_ds = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "\n",
    "# Defining the tensorboard callback, it will log information to the defined log_dir directory\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=dense_log_dir, profile_batch=0)\n",
    "\n",
    "# Train the model\n",
    "dense_model.fit(tr_ds, validation_data=v_ds, epochs=10, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the results of the fully connected model,\n",
    "\n",
    "---\n",
    "## Open [Tensorboard](http://localhost:6006) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the performance of the CNN\n",
    "\n",
    "Now let's define a CNN model, train it and visualize model performance on the TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 16)        4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                31370     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,826\n",
      "Trainable params: 36,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Section 14.2\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "conv_model = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(5,5), strides=(2,2), padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_datetimestamp = datetime.strftime(datetime.now(), log_datetimestamp_format)\n",
    "conv_log_dir = os.path.join(\"logs\",\"conv_{}\".format(log_datetimestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 9s 6ms/step - loss: 0.5908 - accuracy: 0.8208 - val_loss: 0.4049 - val_accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3509 - accuracy: 0.8735 - val_loss: 0.3585 - val_accuracy: 0.8733\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3101 - accuracy: 0.8877 - val_loss: 0.3541 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 5ms/step - loss: 0.2888 - accuracy: 0.8933 - val_loss: 0.3433 - val_accuracy: 0.8835\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 5ms/step - loss: 0.2671 - accuracy: 0.9017 - val_loss: 0.3724 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2573 - accuracy: 0.9046 - val_loss: 0.3830 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2431 - accuracy: 0.9090 - val_loss: 0.3761 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2363 - accuracy: 0.9111 - val_loss: 0.3797 - val_accuracy: 0.8823\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2323 - accuracy: 0.9124 - val_loss: 0.3794 - val_accuracy: 0.8808\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2169 - accuracy: 0.9189 - val_loss: 0.3794 - val_accuracy: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b0b93c9a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "tr_ds, v_ds, ts_ds = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=False)\n",
    "\n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Plot activation histograms every two epochs\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=conv_log_dir, histogram_freq=2, profile_batch=0)\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=10, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the result comparison between the fully connected model and the CNN,\n",
    "\n",
    "---\n",
    "## Open [Tensorboard](http://localhost:6006) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging custom metrics to the TensorBoard\n",
    "\n",
    "Some times, we need to log custom metrics to the TensorBoard to visualize and understand them. Here we train two models with and without batch normalization. Then, to observe the effect of batch normalization on the weight parameters, we will analyze the mean and standard deviation of the absolute weights of the second layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14.3\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "dense_model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),    \n",
    "    layers.Dense(256, activation='relu', name='log_layer'),    \n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "dense_model_bn = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu', name='log_layer_bn'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model_bn.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_datetimestamp = datetime.strftime(datetime.now(), log_datetimestamp_format)\n",
    "exp_log_dir = os.path.join(\"logs\",\"weights_exp_{}\".format(log_datetimestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "\tDone\n",
      "Training epoch 2\n",
      "\tDone\n",
      "Training epoch 3\n",
      "\tDone\n",
      "Training epoch 4\n",
      "\tDone\n",
      "Training epoch 5\n",
      "\tDone\n",
      "Training completed\n",
      "\n",
      "Training epoch 1\n",
      "\tDone\n",
      "Training epoch 2\n",
      "\tDone\n",
      "Training epoch 3\n",
      "\tDone\n",
      "Training epoch 4\n",
      "\tDone\n",
      "Training epoch 5\n",
      "\tDone\n",
      "Training completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Section 14.3\n",
    "\n",
    "# Code listing 14.2\n",
    "def train_model(model, dataset, log_dir, log_layer_name, epochs):    \n",
    "    \n",
    "    # Define the writer\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    step = 0\n",
    "    # Open the writer\n",
    "    with writer.as_default():        \n",
    "        tot_iterations_in_epoch = 0  # Total iterations in an epoch\n",
    "        \n",
    "        # For every epoch\n",
    "        for e in range(epochs):\n",
    "            print(\"Training epoch {}\".format(e+1))\n",
    "            # For every iteration in the epoch\n",
    "            for batch in tr_ds:\n",
    "                # Compute the step\n",
    "                \n",
    "                # Train with one batch\n",
    "                model.train_on_batch(*batch)\n",
    "                # Get the weights of the layer [0] - weights / [1] - bias\n",
    "                w = model.get_layer(log_layer_name).get_weights()[0]\n",
    "                \n",
    "                # Log mean and std of absolute weights\n",
    "                tf.summary.scalar(\"mean_weights\", np.mean(np.abs(w)), step=step)\n",
    "                tf.summary.scalar(\"std_weights\", np.std(np.abs(w)), step=step)\n",
    "                \n",
    "                # Flush to the disk from the buffer\n",
    "                writer.flush()\n",
    "                \n",
    "                step += 1\n",
    "            print('\\tDone')\n",
    "    \n",
    "    print(\"Training completed\\n\")\n",
    "    \n",
    "batch_size = 64\n",
    "tr_ds, _, _ = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "train_model(dense_model, tr_ds, exp_log_dir + '/standard', \"log_layer\", 5)\n",
    "\n",
    "tr_ds, _, _ = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "train_model(dense_model_bn, tr_ds, exp_log_dir + '/bn', \"log_layer_bn\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that you can look at the results in the [TensorBoard](http://localhost:6006)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling models to detect performance bottlenecks\n",
    "\n",
    "Here we will profile a convolutional neural network to undrestand performance bottlenecks and computational intensive parts of the pipeline. To highlight our messages, we will use a slightly complex CNN than the one above.\n",
    "\n",
    "## Download the data\n",
    "\n",
    "Here we will use a dataset containing images of flowers from [this link](https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tar file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "# Section 14.4\n",
    "\n",
    "# Downloading the data\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data', '17flowers.tgz')):\n",
    "    \n",
    "    url=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\"\n",
    "\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    # Write to a file\n",
    "    with open(os.path.join('data', '17flowers.tgz'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "else:\n",
    "    print(\"The tar file already exists.\")\n",
    "\n",
    "if not os.path.exists(os.path.join('data', '17flowers')):\n",
    "    # Write to a file\n",
    "    tarf = tarfile.open(os.path.join(\"data\",\"17flowers.tgz\"))\n",
    "    tarf.extractall(os.path.join('data', '17flowers'))\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code listing 14.3\n",
    "def get_cnn_model():\n",
    "    \n",
    "    conv_model = models.Sequential([\n",
    "        layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=(64,64,3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        layers.Flatten(),        \n",
    "        layers.Dense(512),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.LayerNormalization(),                \n",
    "        layers.Dense(256),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.LayerNormalization(),                \n",
    "        layers.Dense(17),\n",
    "        layers.Activation('softmax', dtype='float32')\n",
    "    ])\n",
    "    return conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_private\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"TF_GPU_THREAD_MODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 10s 118ms/step - loss: 3.0507 - accuracy: 0.2568 - val_loss: 4.2416 - val_accuracy: 0.0760\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 2.3070 - accuracy: 0.3369 - val_loss: 3.3861 - val_accuracy: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b0aee18b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 14.4\n",
    "\n",
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "profile_log_dir = os.path.join(\"logs\",\"profile\")\n",
    "    \n",
    "conv_model = get_cnn_model()\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "#conv_model.summary()\n",
    "\n",
    "def get_flower_datasets(image_dir, batch_size, flatten_images=False):\n",
    "\n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label)\n",
    "    dataset = tf.data.Dataset.list_files(os.path.join(image_dir,'*.jpg'), shuffle=False)\n",
    "\n",
    "    def get_image_and_label(file_path):\n",
    "\n",
    "        tokens = tf.strings.split(file_path, os.path.sep)        \n",
    "        label = (tf.strings.to_number(tf.strings.split(tf.strings.split(tokens[-1],'.')[0], '_')[-1])-1)//80\n",
    "\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "        return tf.image.resize(img, [64, 64]), label\n",
    "\n",
    "    dataset = dataset.map(get_image_and_label).shuffle(400)\n",
    "\n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = dataset.take(250).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = dataset.skip(250).batch(batch_size)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "batch_size = 32\n",
    "tr_ds, v_ds = get_flower_datasets(\n",
    "    os.path.join('data', '17flowers','jpg'), batch_size=batch_size, flatten_images=False\n",
    ")\n",
    "    \n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Profile the model memory/time for 10 batches\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=profile_log_dir, profile_batch=[10, 20])\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=2, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the CNN backed up by TensorBoard profiler findings\n",
    "\n",
    "We are going to introduce the following changes\n",
    "* Optimize the `tf.data` pipeline by incorporating prefetching and parallaized map functions\n",
    "* Use mixed precision training\n",
    "* Use private threads for the GPU to launch kernels\n",
    "\n",
    "GPUs having a CUDA computing capability of more than 7 will be able to run mixed precision computations. If not, you will see an error similar to below.\n",
    "\n",
    "```\n",
    "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
    "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
    "  GeForce GTX 960M, compute capability 5.0\n",
    "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
    "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
    "```\n",
    "\n",
    "If you have the capability, you will see something like,\n",
    "\n",
    "```\n",
    "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
    "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070, compute capability 7.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set_environment\"></a>\n",
    "\n",
    "## Setting Environment Variables\n",
    "\n",
    "To set environment variables you can do the following.\n",
    "\n",
    "### Linux\n",
    "\n",
    "Set the environment variable by,\n",
    "* Opening a terminal \n",
    "* Run `export TF_GPU_THREAD_MODE=gpu_private`\n",
    "* Verify the environment variable is set by calling `echo $TF_GPU_THREAD_MODE`\n",
    "* Open a new shell and start the jupyter notebook server\n",
    "\n",
    "### Windows\n",
    "\n",
    "Set the environment variable by,\n",
    "* From the start menu select `Edit the system environment variables`\n",
    "* Click the button called `environment variables`\n",
    "* Add a new environment variable `TF_GPU_THREAD_MODE=gpu_private` in the opened dialog\n",
    "* Open a new command prompt and start the jupyter notebook server\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "To set environment variables in a conda environment,\n",
    "* Activate the conda environment with `conda activate manning.tf2`\n",
    "* Run `conda env config vars set TF_GPU_THREAD_MODE=gpu_private`\n",
    "* Deactivate and reactivate the environment, for the variable to take effect\n",
    "* Start the jupyter notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_profile_log_dir = os.path.join(\"logs\",\"optimized_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 15s 105ms/step - loss: 3.0047 - accuracy: 0.2856 - val_loss: 3.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 3s 83ms/step - loss: 1.9734 - accuracy: 0.3811 - val_loss: 2.6696 - val_accuracy: 0.1080\n"
     ]
    }
   ],
   "source": [
    "# Section 14.4\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "conv_model = get_cnn_model()\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Code listing 14.4\n",
    "def get_flower_datasets(image_dir, batch_size, flatten_images=False):\n",
    "\n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label)\n",
    "    dataset = tf.data.Dataset.list_files(os.path.join(image_dir,'*.jpg'), shuffle=False)\n",
    "\n",
    "    def get_image_and_label(file_path):\n",
    "\n",
    "        tokens = tf.strings.split(file_path, os.path.sep)        \n",
    "        label = (tf.strings.to_number(tf.strings.split(tf.strings.split(tokens[-1],'.')[0], '_')[-1])-1)//80\n",
    "\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "        return tf.image.resize(img, [64, 64]), label\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        get_image_and_label,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).shuffle(400)\n",
    "\n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = dataset.take(250).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = dataset.skip(250).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "batch_size = 32\n",
    "tr_ds, v_ds = get_flower_datasets(os.path.join('data', '17flowers','jpg'), batch_size=batch_size, flatten_images=False)\n",
    "\n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Profile the model memory/time for 370-410 batches\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=opt_profile_log_dir, profile_batch=[10, 20])\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=2, callbacks=[tb_callback])\n",
    "\n",
    "# Resetting to float32\n",
    "policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data types when using mixed precision training\n",
    "\n",
    "Here we can see how data types automatically changes between inputs, variables and outputs if you use mixed precision training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the layers have the data type: <dtype: 'float16'>\n",
      "Variables in the layers have the data type: <dtype: 'float32'>\n",
      "Output of the layers have the data type: <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "# Section 14.4\n",
    "\n",
    "print(\"Input to the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").input.dtype))\n",
    "print(\"Variables in the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").trainable_variables[0].dtype))\n",
    "print(\"Output of the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").output.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing word vectors on TensorBoard\n",
    "\n",
    "Here, we are going to visualize word vectors on TensorBoard. TensorBoar has a dedicated section to display high dimensional vectors like word vectors. It internally provides dimensionality reduction mechanisms to map word vectors to 2D or 3D planes and analyse the data visually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GloVe word vectors\n",
    "\n",
    "GloVe word vectors are a freely available set of word vectors produced as a part of [this paper](https://nlp.stanford.edu/pubs/glove.pdf). You can find more information on [this website](https://nlp.stanford.edu/projects/glove/) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading\n",
      "\tDone\n",
      "Extracting data\n",
      "\tDone\n"
     ]
    }
   ],
   "source": [
    "# Section 14.5\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(os.path.join('data','glove.6B.zip')):\n",
    "    \n",
    "    print(\"Downloading\")\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','glove.6B.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"\\tDone\")\n",
    "    \n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'glove.6B.50d.txt')):\n",
    "    print(\"Extracting data\")\n",
    "    with zipfile.ZipFile(os.path.join('data','glove.6B.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    print(\"\\tDone\")\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the most common words in the IMDB movie review dataset\n",
    "\n",
    "We will use the IMDB movie review dataset for this exercise. It contains movie reviews written by critics for various movies. We will analyse the word vectors of the most common words appearing in this text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b232f2e006ad4218ac3b7a2ef603d642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52d2d3ae4cf42ee92bd751d81adcd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20b1a9429ef4defbfcd83fac6c0e370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8946be5993154f79bce4e0c9d0601367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7fc1a4bb5346fba88a0730e60e769e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteQD0ELX\\imdb_reviews-train.tfrecord*...…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3f38ed1741477a941b92d68f744f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c414c3aa865f489aa84837c34556fc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteQD0ELX\\imdb_reviews-test.tfrecord*...:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e51cee22b848f89fa1e9643c9adc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffd4903a2714729868ea8739a9986a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteQD0ELX\\imdb_reviews-unsupervised.tfrec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb_reviews downloaded and prepared to ~\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "review_ds = tfds.load('imdb_reviews')\n",
    "train_review_ds = review_ds[\"train\"]\n",
    "\n",
    "corpus = []\n",
    "for data in train_review_ds:      \n",
    "    txt = str(np.char.decode(data[\"text\"].numpy(), encoding='utf-8')).lower()\n",
    "    corpus.append(str(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the most common 5000 words as our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 322198), ('a', 159953), ('and', 158572), ('of', 144462), ('to', 133967), ('is', 104171), ('in', 90527), ('i', 70480), ('this', 69714), ('that', 66292), ('it', 65505), ('/><br', 50935), ('was', 47024), ('as', 45102), ('for', 42843), ('with', 42729), ('but', 39764), ('on', 31619), ('movie', 30887), ('his', 29059), ('are', 28743), ('not', 28597), ('film', 27777), ('you', 27564), ('have', 27344), ('he', 26177), ('be', 25691), ('at', 22731), ('one', 22480), ('by', 21976), ('an', 21240), ('they', 20624), ('from', 19934), ('all', 19740), ('who', 19407), ('like', 18779), ('so', 18099), ('just', 17309), ('or', 16769), ('has', 16570), ('her', 16540), ('about', 16486), (\"it's\", 15970), ('some', 15280), ('if', 15189), ('out', 14510), ('what', 14055), ('very', 13633), ('when', 13609), ('more', 13170), ('there', 13094), ('she', 12234), ('would', 12027), ('even', 12010), ('good', 11926), ('my', 11766), ('only', 11566), ('their', 11317), ('no', 11273), ('really', 11065), ('had', 11042), ('which', 10898), ('can', 10797), ('up', 10776), ('were', 10528), ('see', 10410), ('than', 9807), ('we', 9417), ('-', 9355), ('been', 9074), ('into', 8990), ('get', 8959), ('will', 8926), ('story', 8743), ('much', 8739), ('because', 8736), ('most', 8477), ('how', 8456), ('other', 8229), ('also', 8007), ('first', 7985), ('its', 7963), ('time', 7945), ('do', 7904), (\"don't\", 7879), ('me', 7722), ('great', 7714), ('people', 7676), ('could', 7594), ('make', 7590), ('any', 7507), ('/>the', 7409), ('after', 7118), ('made', 7041), ('then', 6945), ('bad', 6816), ('think', 6773), ('being', 6390), ('many', 6388), ('him', 6385)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = \" \".join(corpus)\n",
    "\n",
    "cnt = Counter(corpus.split())\n",
    "print(cnt.most_common(100))\n",
    "\n",
    "most_common_words = [w for w,_ in cnt.most_common(5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GloVe vectors \n",
    "\n",
    "Here we read the GloVe vectors and only keep the vectors corresponding to the most common words we identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp\\ipykernel_12912\\3791060985.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(os.path.join('data', 'glove.6B.50d.txt'), header=None, index_col=0, sep=None, error_bad_lines=False, encoding='utf-8')\n",
      "C:\\Users\\carlos\\AppData\\Local\\Temp\\ipykernel_12912\\3791060985.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(os.path.join('data', 'glove.6B.50d.txt'), header=None, index_col=0, sep=None, error_bad_lines=False, encoding='utf-8')\n",
      "Skipping line 9: field larger than field limit (131072)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>-0.41242</td>\n",
       "      <td>0.12170</td>\n",
       "      <td>0.34527</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>-0.49688</td>\n",
       "      <td>-0.17862</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.656600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298710</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>-0.347580</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.44251</td>\n",
       "      <td>0.187850</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.184110</td>\n",
       "      <td>-0.115140</td>\n",
       "      <td>-0.78581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.236820</td>\n",
       "      <td>-0.16899</td>\n",
       "      <td>0.40951</td>\n",
       "      <td>0.63812</td>\n",
       "      <td>0.477090</td>\n",
       "      <td>-0.42852</td>\n",
       "      <td>-0.55641</td>\n",
       "      <td>-0.36400</td>\n",
       "      <td>-0.239380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080262</td>\n",
       "      <td>0.630030</td>\n",
       "      <td>0.321110</td>\n",
       "      <td>-0.467650</td>\n",
       "      <td>0.22786</td>\n",
       "      <td>0.360340</td>\n",
       "      <td>-0.378180</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>0.30392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.301770</td>\n",
       "      <td>-0.16763</td>\n",
       "      <td>0.17684</td>\n",
       "      <td>0.31719</td>\n",
       "      <td>0.339730</td>\n",
       "      <td>-0.43478</td>\n",
       "      <td>-0.31086</td>\n",
       "      <td>-0.44999</td>\n",
       "      <td>-0.294860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>0.087939</td>\n",
       "      <td>-0.102850</td>\n",
       "      <td>-0.13931</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>-0.080803</td>\n",
       "      <td>-0.356520</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>0.10216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.570880</td>\n",
       "      <td>-0.47160</td>\n",
       "      <td>0.18048</td>\n",
       "      <td>0.54449</td>\n",
       "      <td>0.726030</td>\n",
       "      <td>0.18157</td>\n",
       "      <td>-0.52393</td>\n",
       "      <td>0.10381</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347270</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>0.075693</td>\n",
       "      <td>-0.062178</td>\n",
       "      <td>-0.38988</td>\n",
       "      <td>0.229020</td>\n",
       "      <td>-0.216170</td>\n",
       "      <td>-0.225620</td>\n",
       "      <td>-0.093918</td>\n",
       "      <td>-0.80375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.680470</td>\n",
       "      <td>-0.039263</td>\n",
       "      <td>0.30186</td>\n",
       "      <td>-0.17792</td>\n",
       "      <td>0.42962</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>-0.41376</td>\n",
       "      <td>0.13228</td>\n",
       "      <td>-0.29847</td>\n",
       "      <td>-0.085253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094375</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>-0.19722</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>-0.094340</td>\n",
       "      <td>-0.073297</td>\n",
       "      <td>-0.064699</td>\n",
       "      <td>-0.26044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2        3        4        5         6        7   \\\n",
       "0                                                                       \n",
       "the  0.418000  0.249680 -0.41242  0.12170  0.34527 -0.044457 -0.49688   \n",
       ",    0.013441  0.236820 -0.16899  0.40951  0.63812  0.477090 -0.42852   \n",
       ".    0.151640  0.301770 -0.16763  0.17684  0.31719  0.339730 -0.43478   \n",
       "of   0.708530  0.570880 -0.47160  0.18048  0.54449  0.726030  0.18157   \n",
       "to   0.680470 -0.039263  0.30186 -0.17792  0.42962  0.032246 -0.41376   \n",
       "\n",
       "          8        9         10  ...        41        42        43        44  \\\n",
       "0                                ...                                           \n",
       "the -0.17862 -0.00066 -0.656600  ... -0.298710 -0.157490 -0.347580 -0.045637   \n",
       ",   -0.55641 -0.36400 -0.239380  ... -0.080262  0.630030  0.321110 -0.467650   \n",
       ".   -0.31086 -0.44999 -0.294860  ... -0.000064  0.068987  0.087939 -0.102850   \n",
       "of  -0.52393  0.10381 -0.175660  ... -0.347270  0.284830  0.075693 -0.062178   \n",
       "to   0.13228 -0.29847 -0.085253  ... -0.094375  0.018324  0.210480 -0.030880   \n",
       "\n",
       "          45        46        47        48        49       50  \n",
       "0                                                              \n",
       "the -0.44251  0.187850  0.002785 -0.184110 -0.115140 -0.78581  \n",
       ",    0.22786  0.360340 -0.378180 -0.566570  0.044691  0.30392  \n",
       ".   -0.13931  0.223140 -0.080803 -0.356520  0.016413  0.10216  \n",
       "of  -0.38988  0.229020 -0.216170 -0.225620 -0.093918 -0.80375  \n",
       "to  -0.19722  0.082279 -0.094340 -0.073297 -0.064699 -0.26044  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'glove.6B.50d.txt'), header=None, index_col=0, sep=None, error_bad_lines=False, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full size of Glove: 399694\n",
      "Size after only considering the most common words: (3595, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Full size of Glove: {}\".format(df.shape[0]))\n",
    "df_common = df.loc[df.index.isin(most_common_words)]\n",
    "print(\"Size after only considering the most common words: {}\".format(df_common.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the word vectors in order to be projected on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3595, 50)\n"
     ]
    }
   ],
   "source": [
    "# Section 14.5\n",
    "\n",
    "# Code listing 14.5\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "log_dir=os.path.join('logs', 'embeddings')\n",
    "\n",
    "# Save the weights we want to analyse as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, so\n",
    "# we will remove that value.\n",
    "weights = tf.Variable(df_common.values)\n",
    "print(weights.shape)\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    for w in df_common.index:\n",
    "        f.write(w+'\\n')\n",
    "        \n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "#embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlighting word vectors\n",
    "\n",
    "There is a section in the word vectors panel where you can search for specific vectors. You can use regex patterns like the one below to search there and highlight specific vectors.\n",
    "\n",
    "`(?:fred|larry|mrs\\.|mr\\.|michelle|sea|denzel|beach|comedy|theater|idiotic|sadistic|marvelous|loving|gorg|bus|truck|lugosi)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate TensorBoard for word vectors\n",
    "\n",
    "We also need a separate TensorBoard service (we will use a different port). As visualizing word vectors, the TensorBoard expects to find the data in a very specific folder. Since for the previous TensorBoard we had already defined a different structure, we'll have to view word vectors in a different TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e7ba00c31d0cfbfb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e7ba00c31d0cfbfb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/embeddings/ --port 6007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Open [Tensorboard for Word Vectors](http://localhost:6007) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manning.tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:51:29) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a5eda5f6f277a35ee74e53c7ea4300c8d4d4a1e37dd21ebec0e7d7b2134f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
